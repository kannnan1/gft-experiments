# R1.2: ResNet-18 LoRA r=8 on CIFAR-10 Even/Odd (DONE âœ…)

experiment:
  name: "resnet50_lora_r8_cifar100-coarse"
  phase: 1
  exp_id: "R1.2"
  seeds: [42]

model:
  architecture: "resnet50"
  method: "lora"
  rank: 8
  pretrained: true

data:
  base_task: "cifar100"
  adapt_task: "coarse"
  batch_size: 4096
  num_workers: 4

training:
  epochs: 20
  learning_rate: 0.001
  optimizer: "sgd"
  weight_decay: 0.01
  scheduler: "cosine"
  warmup_epochs: 0
  
  early_stopping_patience : 10
  early_stopping_delta : 0.01

  skip_stage1: false
  skip_stage2: true
  continue_from_stage1: true
  stage1_checkpoint: "results/checkpoints/R1.2_resnet50_lora_r8_cifar100-coarse_seed42/stage1_final.pt"


logging:
  use_wandb: false
  wandb_project: "gft_finetuning"
  log_interval: 10
  save_interval: 10

evaluation:
  eval_base_task: true
  eval_adaptation_task: true
  compute_geometric_metrics: false

paths:
  data_dir: "./data"
  checkpoint_dir: "./results/checkpoints"
  log_dir: "./results/logs"
